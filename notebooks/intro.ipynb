{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Open this notebook in Colab: https://colab.research.google.com/github/google/sequence-layers/blob/main/notebooks/intro.ipynb**\n",
        "\n",
        "-----\n",
        "\n",
        "SequenceLayers is a new design for neural network layer APIs that enables better sequence processing and streaming inference.\n",
        "\n",
        "**Library:** https://github.com/google/sequence-layers\n",
        "\n",
        "**Whitepaper:** https://github.com/google/sequence-layers/blob/main/tech-report.pdf"
      ],
      "metadata": {
        "id": "YOlPMJ2FX0x2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setup"
      ],
      "metadata": {
        "id": "zq42AFDNQM_r"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SdEXFhqDP1la"
      },
      "outputs": [],
      "source": [
        "!pip install sequence-layers==0.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import flax\n",
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import numpy as np\n",
        "\n",
        "import sequence_layers.jax as sl\n",
        "import sequence_layers.jax.test_utils as sl_test_utils\n",
        "import sequence_layers.jax.utils as sl_utils\n",
        "\n",
        "key = jax.random.key(0)\n",
        "random_sequence = sl_test_utils.random_sequence\n",
        "unbox = flax.core.meta.unbox"
      ],
      "metadata": {
        "id": "4HYD_3XjP9ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iC5OX3sp4e5e"
      },
      "source": [
        "# The Sequence Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLz5_oFc8W0i"
      },
      "outputs": [],
      "source": [
        "#@title A `Sequence` is a PyTree containing `values` and a `mask`. {vertical-output: true}\n",
        "# Values can have any dtype, while mask must be bool.\n",
        "# Values and mask must have a batch and time dimension.\n",
        "\n",
        "x = sl.Sequence(\n",
        "  values=jnp.ones((2, 3, 5)),\n",
        "  mask=jnp.ones((2, 3), jnp.bool_)\n",
        ")\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KcrYAIjo8ozG"
      },
      "outputs": [],
      "source": [
        "#@title You can mask values to zero with `mask_invalid()`. {vertical-output: true}\n",
        "\n",
        "x = sl.Sequence(\n",
        "  jnp.ones((2, 3, 5)),\n",
        "  jnp.asarray([[True, True, False],\n",
        "               [True, False, False]]))\n",
        "x = x.mask_invalid()\n",
        "\n",
        "# Masking twice is a no-op.\n",
        "assert x.mask_invalid() is x\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjoHVnbErWBZ",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Constructing a sequence from values. {vertical-output: true}\n",
        "\n",
        "# When every value is valid, you can use from_values to create an all-True mask.\n",
        "x = sl.Sequence.from_values(jnp.ones((2, 3, 5)))\n",
        "\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgEuctSCrwKX"
      },
      "outputs": [],
      "source": [
        "# @title Constructing a left-aligned sequence from values and lengths. {vertical-output: true}\n",
        "\n",
        "# When every value is valid, you can use from_values to create an all-True mask.\n",
        "x = sl.Sequence.from_lengths(jnp.ones((2, 3, 5)), jnp.array([2, 1]))\n",
        "\n",
        "# from_lengths does not mask the values for you.\n",
        "print(x)\n",
        "print()\n",
        "\n",
        "# The lengths() method tells you how many valid timepoints are in the sequence.\n",
        "print(f'{x.lengths()=}')\n",
        "print()\n",
        "\n",
        "x = x.mask_invalid()\n",
        "x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EFDG88909JHI"
      },
      "outputs": [],
      "source": [
        "#@title A `Sequence` has a `channel_spec`, describing its inner dimensions (minus batch and time).\n",
        "\n",
        "# SequenceLayers process Sequences along the time dimension.\n",
        "# Sequences can represent any data with a time dimension.\n",
        "\n",
        "print('Audio data: [batch, time, features]:')\n",
        "x = sl.Sequence(jnp.ones((2, 3, 5)),\n",
        "                jnp.ones((2, 3), jnp.bool_))\n",
        "print(f'{x.shape=} {x.ndim=} {x.dtype=}')\n",
        "print(f'{x.channel_shape=}')\n",
        "print(f'{x.channel_spec=}')\n",
        "print()\n",
        "\n",
        "print('Text data: [batch, time] tokens:')\n",
        "x = sl.Sequence(jnp.ones((2, 3), jnp.int32),\n",
        "                jnp.ones((2, 3), jnp.bool_))\n",
        "print(f'{x.shape=} {x.ndim=} {x.dtype=}')\n",
        "print(f'{x.channel_shape=}')\n",
        "print(f'{x.channel_spec=}')\n",
        "print()\n",
        "\n",
        "print('Video data (RGB images over time): [batch, time, height, width, channels]:')\n",
        "x = sl.Sequence(jnp.ones((2, 3, 32, 32, 3), jnp.int8),\n",
        "                jnp.ones((2, 3), jnp.bool_))\n",
        "print(f'{x.shape=} {x.ndim=} {x.dtype=}')\n",
        "print(f'{x.channel_shape=}')\n",
        "print(f'{x.channel_spec=}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r8vLjClb4gbB"
      },
      "source": [
        "# The SequenceLayer Type"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpNlbq__4mOp"
      },
      "outputs": [],
      "source": [
        "#@title `sl.SequenceLayerConfig` objects are declarative network specifications.\n",
        "\n",
        "config: sl.SequenceLayerConfig = sl.Serial.Config([\n",
        "  sl.Dense.Config(8, name='dense1', activation=jax.nn.relu),\n",
        "  sl.Dense.Config(8, name='dense2')\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NPJ44Q088MWI"
      },
      "outputs": [],
      "source": [
        "#@title Construct a layer from a `SequenceLayerConfig` with `make()`.\n",
        "model: sl.SequenceLayer = config.make()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyZSR1TI8Pr7"
      },
      "outputs": [],
      "source": [
        "# @title In JAX, `SequenceLayer` is just a Flax layer.\n",
        "\n",
        "# Get variables for a layer with `nn.Module.init`, just like Flax.\n",
        "batch_size, time, channels = 2, 3, 5\n",
        "\n",
        "x = sl.Sequence(\n",
        "    jax.random.uniform(key, (batch_size, time, channels)),\n",
        "    jnp.ones((batch_size, time), dtype=jnp.bool_),\n",
        ")\n",
        "\n",
        "model_vars = model.init(key, x, training=False)\n",
        "sl_utils.pprint_tree_shapes_types(unbox(model_vars))\n",
        "\n",
        "# Bind the model to the variables for imperative demonstration.\n",
        "model = model.bind(model_vars)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x"
      ],
      "metadata": {
        "id": "XRJTBsrmSyq-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G_BWxdLu_Aaw"
      },
      "outputs": [],
      "source": [
        "#@title A `SequenceLayer` has a `layer` and a `step` method.\n",
        "\n",
        "# Process x layer-wise.\n",
        "y = model.layer(x, training=False)\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Process x step-wise (arbitrary block sizes).\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "y0, state = model.step(x[:, 0:2], state, training=False)\n",
        "y1, state = model.step(x[:, 2:4], state, training=False)\n",
        "y2, state = model.step(x[:, 4:6], state, training=False)\n",
        "print(y)"
      ],
      "metadata": {
        "id": "vDJaprikhN5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layer() and step() are required to produce identical results.\n",
        "np.testing.assert_array_almost_equal(\n",
        "    y.values,\n",
        "    jnp.concatenate([y0.values, y1.values, y2.values], axis=1))\n",
        "\n",
        "print('Layer and step produced identical results:')\n",
        "print(y)"
      ],
      "metadata": {
        "id": "IXsBYZaMhSAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The SequenceLayer Contract\n",
        "\n",
        "`SequenceLayer`s must obey the following contract:\n",
        "\n",
        "*   **Layer-wise and step-wise equivalence**: If `SequenceLayer.supports_step`,\n",
        "    `SequenceLayer.layer` and `SequenceLayer.step` must produce identical\n",
        "    results when fed identical data and starting state (slicing the data up into\n",
        "    blocks of multiples of `SequenceLayer.block_size` timesteps.\n",
        "\n",
        "    *   Stateful stochastic layers (e.g. `Dropout`) should obey this property if\n",
        "        RNG state were made deterministic.\n",
        "\n",
        "*   **Padding and batching invariance**: `SequenceLayer.layer` and\n",
        "    `SequenceLayer.step` must produce identical results when fed identical data\n",
        "    with differing amounts of end padding, or when the position of examples in a\n",
        "    batch is shuffled. For the common use-case of batching contiguous sequences\n",
        "    of mixed lengths together, the lengths of other sequences in the batch or\n",
        "    the position in the batch should have no bearing on the calculation\n",
        "    performed by the layer.\n",
        "\n",
        "    Said another way, the physical dimensions of the input `Sequence` `values`\n",
        "    (`[b, t, ...]`) batch size `b` or length `t` must have no impact on the\n",
        "    resulting computation for an individual sequence in the batch. For example,\n",
        "    adding arbitrary amounts of padding to the end of the input `values` must\n",
        "    not change the valid portions of the returned sequence.\n",
        "\n",
        "    *   **Important note:** Padding invariance is currently only required for\n",
        "        end padding. Start padding or interior padding (for non-contiguous\n",
        "        sequences) does affect the behavior of calculations.\n",
        "\n",
        "    *   **Corollary:** Padding values must not affect the calculation of\n",
        "        non-padding values.\n",
        "\n",
        "*   **Masked inputs and outputs**: For an input `Sequence` provided to a\n",
        "    `SequenceLayer` with `values` (`[b, t, ...]`) and `mask` (`[b, t]`),\n",
        "    `SequenceLayer`s **must not assume `values` is masked** (a Sequence is\n",
        "    masked if `values[mask == False] == 0.0`). If the computation performed by\n",
        "    the layer mixes information across timesteps, then the layer must mask the\n",
        "    sequence before use. The layer may return either a `Sequence` or a\n",
        "    `MaskedSequence`.\n",
        "\n",
        "Each `SequenceLayer` offered in the `sl.` namespace has unit tests that it obeys\n",
        "this contract. You can test your own layers obey this contract with\n",
        "[`test_utils.verify_contract`](https://github.com/google/sequence-layers/blob/7a67779f5b8af2b904a1b4aab9b846dd4d6801ae/sequence_layers/jax/test_utils.py#L846C7-L846C22)."
      ],
      "metadata": {
        "id": "oJcFlLjXQSMZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SequenceLayers: State Management for Free"
      ],
      "metadata": {
        "id": "At2zMqM5S-Dt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZaiJD2nwAZYN"
      },
      "outputs": [],
      "source": [
        "#@title What is `state`? An empty PyTree for our `Dense -> Dense` layer. {vertical-output: true}\n",
        "\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "sl_utils.pprint_tree_shapes_types(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mHzBndenAgvs"
      },
      "outputs": [],
      "source": [
        "#@title Let's define a \"stateful\" `SequenceLayer`. What is its state? {vertical-output: true}\n",
        "#@markdown State for two temporal convolutions is two input buffers of length `kernel_size - 1`.\n",
        "\n",
        "config = sl.Serial.Config([\n",
        "  sl.Conv1D.Config(8, kernel_size=4, strides=2, padding='causal', name='conv1'),\n",
        "  sl.Conv1D.Config(8, kernel_size=6, strides=4, padding='causal', name='conv2')\n",
        "])\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "sl_utils.pprint_tree_shapes_types(state)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title (inspecting properties of a layer) {vertical-output: true}\n",
        "print(f\"{model.output_latency=}\")\n",
        "print(f\"{model.output_ratio=}\")\n",
        "print(f\"{model.receptive_field=}\")"
      ],
      "metadata": {
        "id": "M1FKN-xDhwkB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4iqa-LVXlmRe"
      },
      "outputs": [],
      "source": [
        "# @title Let's define a \"stateful\" `SequenceLayer`: Self Attention. {vertical-output: true}\n",
        "# @markdown State for a self attention layer is a KV cache.\n",
        "\n",
        "config: sl.SequenceLayerConfig = sl.Serial.Config([\n",
        "    sl.DotProductSelfAttention.Config(\n",
        "        units_per_head=2, num_heads=8, max_past_horizon=32\n",
        "    ),\n",
        "    sl.EinsumDense.Config('...nh,nhd->...d', output_shape=[16]),\n",
        "])\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "sl_utils.pprint_tree_shapes_types(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oE8fmppJmKxT"
      },
      "outputs": [],
      "source": [
        "#@title Let's define a \"stateful\" `SequenceLayer`: LSTM {vertical-output: true}\n",
        "#@markdown State for an LSTM layer is the fixed size state array.\n",
        "\n",
        "config = sl.LSTM.Config(units=32)\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "sl_utils.pprint_tree_shapes_types(state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fc603msI_rC9"
      },
      "outputs": [],
      "source": [
        "#@title A SequenceLayer has a `block_size` and an `output_ratio`. {vertical-output: true}\n",
        "\n",
        "config = sl.Serial.Config([\n",
        "  sl.Conv1D.Config(8, kernel_size=4, strides=2, padding='causal', name='conv1'),\n",
        "  sl.Conv1D.Config(8, kernel_size=6, strides=4, padding='causal', name='conv2')\n",
        "])\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "# Two convolutions of stride 2 and 4 means we must feed 8 inputs to get 1 output,\n",
        "# and we must feed inputs in multiples of 8 to the `step` function.\n",
        "print('output_ratio: The number of output timesteps for one input as a fraction.')\n",
        "print(f'{model.output_ratio=}\\n')\n",
        "print('block_size: Multiple of timesteps required as input to step.')\n",
        "print(f'{model.block_size=}\\n')\n",
        "\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "\n",
        "# Step requires a sequence whose physical length is a multiple of the block size.\n",
        "x = random_sequence(2, 24, *x.channel_shape)\n",
        "y, state = model.step(x, state, training=False)\n",
        "\n",
        "# The output ratio determines the physical length of the resulting sequence.\n",
        "print(f'Input sequence: {x.shape} -> Output sequence: {y.shape}')\n",
        "assert y.shape[1] == x.shape[1] * model.output_ratio\n",
        "\n",
        "# x.shape is not a multiple of block_size, so the step fails:\n",
        "x = random_sequence(2, 23, *x.channel_shape)\n",
        "try:\n",
        "  model.step(x, state, training=False)\n",
        "except ValueError as e:\n",
        "  print(f'Input sequence: {x.shape} -> Error {e}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GFq7qubYCKsG"
      },
      "outputs": [],
      "source": [
        "#@title Stepping with multiples of `block_size` at a time.\n",
        "\n",
        "# We have to feed inputs to step 8 timesteps at a time, since model.block_size is 8.\n",
        "# Any multiple of block_size is supported as an input to step.\n",
        "# If block_size > 1, causality is still preserved.\n",
        "\n",
        "batch_size, time, channels = 2, 32, 5\n",
        "\n",
        "x = sl.Sequence(\n",
        "  jax.random.uniform(key, (batch_size, time, channels)),\n",
        "  jnp.ones((batch_size, time), dtype=jnp.bool_))\n",
        "\n",
        "# Process x layer-wise.\n",
        "y = model.layer(x, training=False)\n",
        "\n",
        "# Process x step-wise in blocks of block_size.\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "y0, state = model.step(x[:, 0:8], state, training=False)\n",
        "y1, state = model.step(x[:, 8:16], state, training=False)\n",
        "y2, state = model.step(x[:, 16:24], state, training=False)\n",
        "y3, state = model.step(x[:, 24:32], state, training=False)\n",
        "\n",
        "np.testing.assert_array_almost_equal(\n",
        "    y.values,\n",
        "    jnp.concatenate([y0.values, y1.values, y2.values, y3.values], axis=1))\n",
        "\n",
        "# Process x step-wise in blocks of `2 * block_size`.\n",
        "state = model.get_initial_state(batch_size, x.channel_spec, training=False)\n",
        "y0, state = model.step(x[:, 0:16], state, training=False)\n",
        "y1, state = model.step(x[:, 16:32], state, training=False)\n",
        "\n",
        "np.testing.assert_array_almost_equal(\n",
        "    y.values,\n",
        "    jnp.concatenate([y0.values, y1.values], axis=1))\n",
        "\n",
        "print('Layer and step produced identical results:')\n",
        "print(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nZt0c25jkboq"
      },
      "outputs": [],
      "source": [
        "# @title `constants`: Side inputs to SequenceLayers. {vertical-output: true}\n",
        "# @markdown `get_initial_state`, `step` and `layer` have an optional `constants: dict[str, jax.Array | sl.Sequence]` argument. This is used to provide side-inputs to layers, for example conditioning information, source sequences for cross attention, control parameters (CFG scale, temperature if sampling happens internally to a SequenceLayer), etc.\n",
        "\n",
        "config = sl.DotProductAttention.Config(\n",
        "    source_name='source', num_heads=8, units_per_head=3\n",
        ")\n",
        "\n",
        "x = random_sequence(2, 16, 3)\n",
        "source = random_sequence(2, 7, 5)\n",
        "\n",
        "constants = {'source': source}\n",
        "print('We provide the source for cross attention in constants:')\n",
        "sl_utils.pprint_tree_shapes_types(constants)\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False, constants=constants)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "print()\n",
        "print(\n",
        "    'State contains pre-computed KV caches for the cross attention to source:'\n",
        ")\n",
        "state = model.get_initial_state(\n",
        "    batch_size, x.channel_spec, training=False, constants=constants\n",
        ")\n",
        "sl_utils.pprint_tree_shapes_types(state)\n",
        "\n",
        "y = model.layer(x, training=False, constants=constants)\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(\n",
        "    model, x, training=False, constants=constants\n",
        ")\n",
        "\n",
        "np.testing.assert_array_almost_equal(y.values, y_step.values)\n",
        "\n",
        "print('Layer and step produced identical results:')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vtG6FVXF7rd"
      },
      "source": [
        "# Input and Output Latency\n",
        "\n",
        "`SequenceLayer`s have both an `input_latency` and `output_latency` property\n",
        "describing the latency properties of their step-wise behavior in relation to\n",
        "their layer-wise behavior.\n",
        "\n",
        "*   **Input Latency**: An `int` denoting the number of input timesteps before\n",
        "    the step-wise output of the layer matches its layer-wise output.\n",
        "\n",
        "*   **Output Latency**: A `fractions.Fraction`, the number of output timesteps\n",
        "    before the step-wise output of the layer matches its layer-wise output.\n",
        "\n",
        "An invariant that all layers must maintain is that for the layer-wise output and\n",
        "step-wise output, the step-wise output is equivalent to the layer-wise output\n",
        "**after** appending an additional `input_latency` invalid timesteps at the end\n",
        "of the step-wise input, and dropping the initial `output_latency` timesteps from\n",
        "the step-wise output. The initial `output_latency` timesteps must be invalid\n",
        "(`mask = False`) to avoid accidental use by consumers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-xG4nYFhFzD6"
      },
      "outputs": [],
      "source": [
        "#@title Convolution with lookahead. {vertical-output: true}\n",
        "\n",
        "x = random_sequence(2, 18, 1, random_lengths=False)\n",
        "config = sl.Conv1D.Config(1, kernel_size=5, strides=1, padding='reverse_causal')\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "y_layer = model.layer(x, training=False).mask_invalid()\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x, training=False)\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "#@markdown A `reverse_causal` padded kernel size 5 convolution has a lookahead of 4 timesteps.\n",
        "print(f'Input latency: {model.input_latency}')\n",
        "print(f'Output latency: {model.output_latency}')\n",
        "print()\n",
        "print('The step-wise output does not match the layer-wise output. There are 4 invalid timesteps at the start, and not all outputs are produced!')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x.pad_time(0, model.input_latency, valid=False), training=False)\n",
        "y_step = y_step[:, int(model.output_latency):]\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "print()\n",
        "print('By padding the input and trimming the output, we achieve layer/step equivalence:')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "np.testing.assert_allclose(y_layer.values, y_step.values, atol=1e-6, rtol=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YcC5A1rAKJYi"
      },
      "outputs": [],
      "source": [
        "#@title Self attention with lookahead. {vertical-output: true}\n",
        "\n",
        "x = random_sequence(2, 18, 1, random_lengths=False)\n",
        "config = sl.Serial.Config([\n",
        "    sl.DotProductSelfAttention.Config(num_heads=1, units_per_head=1, max_past_horizon=5, max_future_horizon=5),\n",
        "    sl.Flatten.Config()\n",
        "])\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "y_layer = model.layer(x, training=False).mask_invalid()\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x, training=False)\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "print(f'Input latency: {model.input_latency}')\n",
        "print(f'Output latency: {model.output_latency}')\n",
        "print()\n",
        "print('The step-wise output does not match the layer-wise output. There are 5 invalid timesteps at the start, and not all outputs are produced!')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x.pad_time(0, model.input_latency, valid=False), training=False)\n",
        "y_step = y_step[:, int(model.output_latency):]\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "print()\n",
        "print('By padding the input and trimming the output, we achieve layer/step equivalence:')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "np.testing.assert_allclose(y_layer.values, y_step.values, atol=1e-6, rtol=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEe_7R3nTOuU"
      },
      "outputs": [],
      "source": [
        "#@title `sl.Delay`, an example of `input_latency != output_latency`. {vertical-output: true}\n",
        "\n",
        "x = random_sequence(2, 18, 1, random_lengths=False)\n",
        "config = sl.Delay.Config(3)\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "y_layer = model.layer(x, training=False).mask_invalid()\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x, training=False)\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "#@markdown `sl.Delay` delays both the layer-wise output and step-wise output by default. As a result, the output latency is zero (no trimming is required for step-wise out to match the layer-wise output), but the input latency is > 0 (flushing required to consume all input).\n",
        "print(f'Input latency: {model.input_latency}')\n",
        "print(f'Output latency: {model.output_latency}')\n",
        "print()\n",
        "print('The step-wise output does not match the layer-wise output. Not all outputs are produced without flushing.')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x.pad_time(0, model.input_latency, valid=False), training=False)\n",
        "y_step = y_step[:, int(model.output_latency):]\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "print()\n",
        "print('By padding the input, we achieve layer/step equivalence:')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "np.testing.assert_allclose(y_layer.values, y_step.values, atol=1e-6, rtol=1e-6)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av8YJSg-VP6t"
      },
      "outputs": [],
      "source": [
        "#@title `sl.Lookahead`, an example of `input_latency != output_latency`. {vertical-output: true}\n",
        "\n",
        "x = random_sequence(2, 18, 1, random_lengths=False)\n",
        "config = sl.Lookahead.Config(3)\n",
        "\n",
        "model = config.make()\n",
        "model_vars = model.init(key, x, training=False)\n",
        "model = model.bind(model_vars)\n",
        "\n",
        "y_layer = model.layer(x, training=False).mask_invalid()\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x, training=False)\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "#@markdown `sl.Lookahead` truncates both the layer-wise output and step-wise output by default. As a result, the input latency is zero (no flushing is required for step-wise out to match the layer-wise output), but the output latency is > 0 (trimming of the output is required).\n",
        "print(f'Input latency: {model.input_latency}')\n",
        "print(f'Output latency: {model.output_latency}')\n",
        "print()\n",
        "print('The step-wise output does not match the layer-wise output. The step-wise output needs trimming at the front.')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "y_step, _, _ = sl_utils.step_by_step_dynamic(model, x.pad_time(0, model.input_latency, valid=False), training=False)\n",
        "y_step = y_step[:, int(model.output_latency):]\n",
        "y_step = y_step.mask_invalid()\n",
        "\n",
        "print()\n",
        "print('By trimming the output, we achieve layer/step equivalence:')\n",
        "print(y_layer.values[0, :, 0])\n",
        "print(y_step.values[0, :, 0])\n",
        "\n",
        "np.testing.assert_allclose(y_layer.values, y_step.values, atol=1e-6, rtol=1e-6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1M6GL7trIL5L"
      },
      "source": [
        "# Examples\n",
        "\n",
        "Let's build some example `SequenceLayer` models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kDKsgFwC9abu"
      },
      "outputs": [],
      "source": [
        "#@title Example: Streamable Log mel Spectrogram Frontend\n",
        "\n",
        "sample_rate = 24000.0\n",
        "frame_length = 1200 #@param { type: \"integer\" }\n",
        "frame_step =  300#@param { type: \"integer\" }\n",
        "fft_length =  2048#@param { type: \"integer\" }\n",
        "num_mel_bins = 128 #@param { type: \"integer\" }\n",
        "lower_edge_hertz = 20.0  #@param { type: \"number\" }\n",
        "upper_edge_hertz = 12000.0  #@param { type: \"number\" }\n",
        "log_offset = 1e-6 #@param { type: \"number\" }\n",
        "time_padding = 'causal' #@param ['reverse_causal', 'causal', 'valid']\n",
        "fft_padding = 'center' #@param ['right', 'center']\n",
        "\n",
        "frontend = sl.Serial.Config([\n",
        "  sl.STFT.Config(frame_length,\n",
        "          frame_step,\n",
        "          fft_length,\n",
        "          output_magnitude=True,\n",
        "          fft_padding=fft_padding,\n",
        "          time_padding=time_padding),\n",
        "  sl.LinearToMelSpectrogram.Config(num_mel_bins, sample_rate, lower_edge_hertz, upper_edge_hertz),\n",
        "  sl.Add.Config(1e-6),  # log offset to avoid blowup.\n",
        "  sl.Log.Config(),\n",
        "]).make()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXK3FkVOO9-n"
      },
      "outputs": [],
      "source": [
        "#@title Example: Transformer Encoder\n",
        "\n",
        "def SelfAttentionNetwork(model_dimension, dropout_rate, num_heads, units_per_head, max_past_horizon, max_future_horizon):\n",
        "  return sl.Residual.Config([\n",
        "    sl.RMSNormalization.Config(name='rms_norm'),\n",
        "    sl.DotProductSelfAttention.Config(\n",
        "      units_per_head=units_per_head,\n",
        "      num_heads=num_heads,\n",
        "      max_past_horizon=max_past_horizon,\n",
        "      max_future_horizon=max_future_horizon,\n",
        "      use_bias=False,\n",
        "      # Use RoPE for the queries and keys.\n",
        "      query_network=sl.ApplyRotaryPositionalEncoding.Config(max_wavelength=10000),\n",
        "      key_network=sl.ApplyRotaryPositionalEncoding.Config(max_wavelength=10000),\n",
        "      attention_probabilities_dropout_rate=dropout_rate,\n",
        "      broadcast_dropout_across_queries=True,\n",
        "      name='attention'),\n",
        "    sl.DenseShaped.Config([model_dimension], use_bias=False, name='output_projection'),\n",
        "    sl.Dropout.Config(dropout_rate)\n",
        "  ], name='self_attention')\n",
        "\n",
        "def FeedForwardNetwork(model_dimension: int, ffn_dim: int, dropout_rate: float):\n",
        "  \"\"\"Residual feed-forward module.\"\"\"\n",
        "  return sl.Residual.Config([\n",
        "    sl.RMSNormalization.Config(name='rms_norm'),\n",
        "    sl.Dense.Config(ffn_dim * 2, use_bias=False, name='dense1'),\n",
        "    sl.GatedUnit.Config(jax.nn.gelu, None),  # GeGLU\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "    sl.Dense.Config(model_dimension, use_bias=False, name='dense2'),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "  ], name='ffn')\n",
        "\n",
        "def Transformer(model_dimension: int,\n",
        "                num_layers: int,\n",
        "                num_heads: int,\n",
        "                units_per_head: int,\n",
        "                ffn_dim: int,\n",
        "                dropout_rate: float,\n",
        "                max_past_horizon: int,\n",
        "                max_future_horizon: int) -> sl.SequenceLayerConfig:\n",
        "  return sl.Serial.Config([\n",
        "      sl.AddTimingSignal.Config(),\n",
        "      # Project to model_dimension for Repeat.\n",
        "      sl.Dense.Config(model_dimension, use_bias=False, activation=jax.nn.relu, name='input_projection'),\n",
        "      sl.Repeat.Config(\n",
        "        sl.Serial.Config([\n",
        "          SelfAttentionNetwork(model_dimension, dropout_rate, num_heads, units_per_head, max_past_horizon, max_future_horizon),\n",
        "          FeedForwardNetwork(model_dimension, ffn_dim, dropout_rate),\n",
        "        ], name='transformer_block'),\n",
        "        num_repeats=num_layers,\n",
        "        name='transformer_blocks'),\n",
        "      sl.RMSNormalization.Config(name='output_rms_norm'),\n",
        "    ], name='transformer')\n",
        "\n",
        "\n",
        "layer = Transformer(\n",
        "    model_dimension=1024,\n",
        "    num_layers=2,\n",
        "    num_heads=16,\n",
        "    units_per_head=64,\n",
        "    ffn_dim=4096,\n",
        "    dropout_rate=0.1,\n",
        "    # Unmasked self attention.\n",
        "    max_past_horizon=-1,\n",
        "    max_future_horizon=-1\n",
        ").make()\n",
        "key = jax.random.PRNGKey(42)\n",
        "x = random_sequence(2, 32, 5)\n",
        "layer_vars = layer.init(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzDT61wRqrnH"
      },
      "outputs": [],
      "source": [
        "#@title Example: Causal Conformer\n",
        "\n",
        "def MultiHeadedSelfAttention(\n",
        "    hidden_size: int,\n",
        "    num_heads: int,\n",
        "    max_horizon: int,\n",
        "    dropout_rate: float,\n",
        "    name: str,\n",
        "):\n",
        "  \"\"\"Multi-headed self attention module.\"\"\"\n",
        "  return sl.Residual.Config([\n",
        "    sl.LayerNormalization.Config(),\n",
        "    sl.LocalDotProductSelfAttention.Config(\n",
        "      num_heads=num_heads,\n",
        "      block_size=max_horizon,\n",
        "      units_per_head=hidden_size // num_heads,\n",
        "      max_past_horizon=max_horizon,\n",
        "      max_future_horizon=0,\n",
        "      attention_probabilities_dropout_rate=dropout_rate,\n",
        "    ),\n",
        "    sl.DenseShaped.Config([hidden_size]),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "  ], name=name)\n",
        "\n",
        "\n",
        "def FeedForwardModule(hidden_size: int, dropout_rate: float, name: str):\n",
        "  return sl.Residual.Config([\n",
        "    sl.LayerNormalization.Config(),\n",
        "    sl.Dense.Config(4 * hidden_size, activation=jax.nn.swish),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "    sl.Dense.Config(hidden_size),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "    sl.Scale.Config(0.5)\n",
        "  ], name=name)\n",
        "\n",
        "\n",
        "def ConvolutionModule(hidden_size: int, dropout_rate: float, name: str):\n",
        "  return sl.Residual.Config([\n",
        "    sl.LayerNormalization.Config(),\n",
        "    sl.Dense.Config(2 * hidden_size),\n",
        "    sl.GatedLinearUnit.Config(),\n",
        "    sl.DepthwiseConv1D.Config(kernel_size=32, padding='causal'),\n",
        "    sl.BatchNormalization.Config(),\n",
        "    sl.Swish.Config(),\n",
        "    sl.Dense.Config(hidden_size),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "  ], name=name)\n",
        "\n",
        "\n",
        "def ConformerBlock(\n",
        "    hidden_size: int,\n",
        "    dropout_rate: float,\n",
        "    max_horizon: int,\n",
        "    name: str,\n",
        "    num_heads: int = 8,\n",
        "):\n",
        "  return sl.Serial.Config([\n",
        "    FeedForwardModule(hidden_size, dropout_rate, name='feedforward_start'),\n",
        "    MultiHeadedSelfAttention(hidden_size, num_heads, max_horizon, dropout_rate, name='mhsa'),\n",
        "    ConvolutionModule(hidden_size, dropout_rate, name='lconv'),\n",
        "    FeedForwardModule(hidden_size, dropout_rate, name='feedforward_end'),\n",
        "    sl.LayerNormalization.Config(),\n",
        "  ], name=name)\n",
        "\n",
        "\n",
        "def ConvolutionSubsampling(hidden_size: int):\n",
        "  return sl.Serial.Config([\n",
        "    sl.ExpandDims.Config(-1),\n",
        "    # \"Convolutional subsampling\". Reduce rate by 4x.\n",
        "    sl.Conv2D.Config(\n",
        "        filters=hidden_size,\n",
        "        kernel_size=3,\n",
        "        strides=2,\n",
        "        time_padding='causal',\n",
        "    ),\n",
        "    sl.GroupNormalization.Config(num_groups=1, cumulative=True),\n",
        "    sl.Relu.Config(),\n",
        "    sl.Conv2D.Config(\n",
        "        filters=hidden_size,\n",
        "        kernel_size=3,\n",
        "        strides=2,\n",
        "        time_padding='causal',\n",
        "    ),\n",
        "    sl.GroupNormalization.Config(num_groups=1, cumulative=True),\n",
        "    sl.Relu.Config(),\n",
        "  ], name='convolutional_subsampling')\n",
        "\n",
        "\n",
        "def ConformerEncoder(\n",
        "    hidden_size: int,\n",
        "    num_blocks: int,\n",
        "    max_horizon: int,\n",
        "    dropout_rate: float = 0.1,\n",
        "    name: str | None = None,\n",
        "):\n",
        "  return sl.Serial.Config([\n",
        "    ConvolutionSubsampling(hidden_size),\n",
        "    sl.DenseShaped.Config([hidden_size]),\n",
        "    sl.AddTimingSignal.Config(),\n",
        "    sl.Dropout.Config(dropout_rate),\n",
        "    sl.Repeat.Config(ConformerBlock(\n",
        "        hidden_size,\n",
        "        dropout_rate,\n",
        "        max_horizon,\n",
        "        name='conformer_block'\n",
        "    ), num_repeats=num_blocks),\n",
        "  ], name=name or 'conformer')\n",
        "\n",
        "layer = ConformerEncoder(1024, num_blocks=8, max_horizon=128).make()\n",
        "\n",
        "x = random_sequence(2, 32, 128)\n",
        "layer_vars = layer.init(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "\n",
        "y = layer.layer(x, training=False)\n",
        "\n",
        "state = layer.get_initial_state(2, x.channel_spec, training=False)\n",
        "ys = []\n",
        "for i in range(8):\n",
        "  yi, state = layer.step(x[:, i * 4 : (i+1) * 4], state, training=False)\n",
        "  ys.append(yi)\n",
        "y_step = sl.Sequence.concatenate_sequences(ys)\n",
        "\n",
        "np.testing.assert_allclose(y.values, y_step.values, atol=1e-4, rtol=1e-4)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "in9yPWzEHvTV"
      },
      "source": [
        "# Combinators\n",
        "\n",
        "Combinators are `SequenceLayer`s that allow you to compose or combine other layers using common patterns (e.g. serial and parallel computation). These layers enable you to build complex models without having to resort to creating custom layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b9tWcjREXEei"
      },
      "outputs": [],
      "source": [
        "#@title Combinators: Serial. {vertical-output: true}\n",
        "\n",
        "#@markdown A serial combinator applies the layers provided to it sequentially.\n",
        "\n",
        "# A simple Conv-BN-Relu block. Layers are applied in order.\n",
        "layer = sl.Serial.Config([\n",
        "  sl.Conv2D.Config(8, kernel_size=[5, 3], strides=[2, 1], time_padding='causal', spatial_padding='same', name='conv'),\n",
        "  sl.BatchNormalization.Config(name='bn'),\n",
        "  sl.Relu.Config(),\n",
        "], name='conv_bn_relu').make()\n",
        "\n",
        "x = random_sequence(2, 32, 5, 1)\n",
        "y, layer_vars = layer.init_with_output(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "print(f'Input: {x.shape}')\n",
        "print(f'Output: {y.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-gMeUW2XbWt"
      },
      "outputs": [],
      "source": [
        "#@title Combinators: Residual. {vertical-output: true}\n",
        "\n",
        "#@markdown A residual combinator applies the layers provided to it sequentially, then adds the input back to the output.\n",
        "\n",
        "# A simple residual Conv-BN-Relu block.\n",
        "layer = sl.Residual.Config([\n",
        "  sl.Conv2D.Config(8, kernel_size=[5, 3], strides=1, time_padding='causal', spatial_padding='same', name='conv'),\n",
        "  sl.BatchNormalization.Config(name='bn'),\n",
        "  sl.Relu.Config(),\n",
        "], name='conv_bn_relu').make()\n",
        "\n",
        "x = random_sequence(2, 32, 5, 8)\n",
        "y, layer_vars = layer.init_with_output(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "print(f'Input: {x.shape}')\n",
        "print(f'Output: {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2tY4icgSRY7o"
      },
      "outputs": [],
      "source": [
        "#@title Combinators: Bidirectional. {vertical-output: true}\n",
        "\n",
        "#@markdown The bidirectional combinator processes the input sequence forward with the forward network and\n",
        "#@markdown in reverse with the backward network, then combines them according to a combination function.\n",
        "\n",
        "layer = sl.Bidirectional.Config(\n",
        "    forward=sl.Serial.Config([\n",
        "        sl.Conv2D.Config(\n",
        "            8,\n",
        "            kernel_size=5,\n",
        "            strides=2,\n",
        "            time_padding='reverse_causal',\n",
        "            spatial_padding='same',\n",
        "        ),\n",
        "        sl.BatchNormalization.Config(),\n",
        "        sl.Relu.Config(),\n",
        "    ]),\n",
        "    backward=sl.Serial.Config([\n",
        "        sl.Conv2D.Config(\n",
        "            8,\n",
        "            kernel_size=5,\n",
        "            strides=2,\n",
        "            time_padding='reverse_causal',\n",
        "            spatial_padding='same',\n",
        "        ),\n",
        "        sl.BatchNormalization.Config(),\n",
        "        sl.Relu.Config(),\n",
        "    ]),\n",
        "    combination=sl.CombinationMode.STACK,\n",
        "    name='bidirectional_conv2d',\n",
        ").make()\n",
        "\n",
        "batch_size, time, height, channels = 2, 32, 5, 1\n",
        "x = random_sequence(2, 32, 5, 1)\n",
        "y, layer_vars = layer.init_with_output(key, x, training=False)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "print(f'Input: {x.shape}')\n",
        "print(f'Output: {y.shape}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "El62-MovoA_d"
      },
      "outputs": [],
      "source": [
        "#@title Combinators: Repeat. {vertical-output: true}\n",
        "\n",
        "#@markdown The repeat combinator repeats the provided network specification multiple times with different variables on each repeat.\n",
        "#@markdown This allows compile time savings since the loop body only has to be compiled once.\n",
        "#@markdown Can be combined with CheckpointGradient to save memory in addition to compile time.\n",
        "\n",
        "layer = sl.Repeat.Config(\n",
        "    sl.Serial.Config([\n",
        "        sl.Conv2D.Config(8, kernel_size=5, strides=1, time_padding='reverse_causal', spatial_padding='same'),\n",
        "        sl.BatchNormalization.Config(),\n",
        "        sl.Relu.Config(),\n",
        "    ]),\n",
        "    num_repeats=3).make()\n",
        "\n",
        "x = random_sequence(2, 32, 5, 8)\n",
        "y, layer_vars = layer.init_with_output(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "print(f'Input: {x.shape}')\n",
        "print(f'Output: {y.shape}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Ay4Nae4oVAf"
      },
      "outputs": [],
      "source": [
        "#@title Combinators: CheckpointGradient. {vertical-output: true}\n",
        "\n",
        "#@markdown The CheckpointGradient combinator wraps the provided body in a gradient checkpoint\n",
        "#@markdown scope so the intermediate tensors are discarded according to the provided policy,\n",
        "#@markdown and recomputed in the backward pass.\n",
        "\n",
        "layer = sl.CheckpointGradient.Config(\n",
        "    sl.Serial.Config([\n",
        "        sl.Conv2D.Config(8, kernel_size=5, strides=1, time_padding='reverse_causal', spatial_padding='same'),\n",
        "        sl.BatchNormalization.Config(),\n",
        "        sl.Relu.Config(),\n",
        "    ])).make()\n",
        "\n",
        "x = random_sequence(2, 32, 5, 8)\n",
        "y, layer_vars = layer.init_with_output(key, x, training=False)\n",
        "layer_vars = unbox(layer_vars)\n",
        "layer = layer.bind(layer_vars)\n",
        "sl_utils.pprint_tree_shapes_types(layer_vars)\n",
        "print(f'Input: {x.shape}')\n",
        "print(f'Output: {y.shape}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6w3kgMqlFfOj"
      },
      "source": [
        "# What's a SequenceLayer useful for?\n",
        "\n",
        "They are a useful building block anywhere in your system that you have a sequence-in / sequence-out block where it doesn't matter what the implementation is. Additionally, when combined with a global pooling operation they can be useful as a sequence-to-vector primitive.\n",
        "\n",
        "SequenceLayers have been used as components of:\n",
        "* Diffusion models\n",
        "* Autoregressive models\n",
        "* Flows\n",
        "* GANs\n",
        "* LLMs (Gemma 3n, DolphinGemma)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w97rfSJFuID4"
      },
      "source": [
        "# Example: Model-independent Autoregressive Sampling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import abc\n",
        "import dataclasses\n",
        "\n",
        "import flax.linen as nn"
      ],
      "metadata": {
        "id": "zCopfZKQVpVn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00TUUaoqGnoF",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Distribution helper. Not part of SequenceLayers, but a useful abstraction over distributions.\n",
        "\n",
        "from tensorflow_probability.substrates import jax as tfp\n",
        "tfd = tfp.distributions\n",
        "\n",
        "class DistributionLayer(nn.Module, metaclass=abc.ABCMeta):\n",
        "\n",
        "  @property\n",
        "  @abc.abstractmethod\n",
        "  def event_spec(self) -> jax.ShapeDtypeStruct:\n",
        "    pass\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def get_distribution(hidden: sl.Sequence, training: bool) -> tfd.Distribution:\n",
        "    pass\n",
        "\n",
        "  def __call__(self, x: sl.Sequence) -> tfd.Distribution:\n",
        "    \"\"\"For Flax compatibility.\"\"\"\n",
        "    return self.get_distribution(x, training=False)\n",
        "\n",
        "\n",
        "class DistributionLayerConfig(metaclass=abc.ABCMeta):\n",
        "\n",
        "  @abc.abstractmethod\n",
        "  def make(self) -> DistributionLayer:\n",
        "    pass\n",
        "\n",
        "\n",
        "class Categorical(DistributionLayer):\n",
        "\n",
        "  @dataclasses.dataclass(frozen=True)\n",
        "  class Config(DistributionLayerConfig):\n",
        "    num_classes: int\n",
        "\n",
        "    def make(self) -> 'Categorical':\n",
        "      return Categorical(self)\n",
        "\n",
        "  config: Config\n",
        "\n",
        "  @property\n",
        "  def event_spec(self) -> jax.ShapeDtypeStruct:\n",
        "    return jax.ShapeDtypeStruct([], jnp.int32)\n",
        "\n",
        "  @nn.compact\n",
        "  def get_distribution(self, hidden: sl.Sequence, training: bool) -> tfd.Distribution:\n",
        "    l = sl.Dense.Config(self.config.num_classes, use_bias=False, name='to_logits').make()\n",
        "    logits = l.layer(hidden, training=training)\n",
        "    return tfd.Categorical(logits=logits.values)\n",
        "\n",
        "key = jax.random.PRNGKey(42)\n",
        "x = sl.Sequence(jnp.ones((2, 3), jnp.int32), jnp.ones((2, 3), jnp.bool_))\n",
        "h = sl.Sequence(jnp.ones((2, 3, 5)), jnp.ones((2, 3), jnp.bool_))\n",
        "l = Categorical.Config(num_classes=10).make()\n",
        "l = l.bind(l.init(key, h))\n",
        "sl_utils.pprint_tree_shapes_types(unbox(l.variables))\n",
        "dist = l.get_distribution(h, training=False)\n",
        "\n",
        "assert dist.event_shape == []\n",
        "assert dist.batch_shape == [2, 3]\n",
        "assert dist.dtype == jnp.int32\n",
        "\n",
        "log_probs = x.apply_values(dist.log_prob).mask_invalid()\n",
        "print(log_probs)\n",
        "samples = sl.Sequence(dist.sample(sample_shape=(), seed=key), h.mask).mask_invalid()\n",
        "print(samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gS8A0f3F4UA9"
      },
      "outputs": [],
      "source": [
        "# @title Using a SequenceLayer as an autoregressive step function {vertical-output: true}\n",
        "# @markdown `SequenceLayer`s are handy for designing the step function of an autoregressive model, since they can be efficiently executed in a parallel layer-wise fashion (\"teacher forcing\" for likelihood evaluation) in training and executed step-by-step at sampling time.\n",
        "# @markdown\n",
        "# @markdown The implementation of the step function (e.g. Transformer vs. RNN vs. convolution) **does not matter at all** for the autoregressive math, and the implementation should not be coupled to those details.\n",
        "\n",
        "\n",
        "class AutoregressiveDecoder(nn.Module):\n",
        "  \"\"\"An autoregressive model. Note, *not* a SequenceLayer.\"\"\"\n",
        "\n",
        "  @dataclasses.dataclass(frozen=True)\n",
        "  class Config:\n",
        "    # The step function to map from x_{t-1} to h_t.\n",
        "    body: sl.SequenceLayerConfig\n",
        "    # The conditional distribution expressing p(x_t | h_t).\n",
        "    distribution: DistributionLayerConfig\n",
        "    # An optional name for the decoder.\n",
        "    name: str | None = None\n",
        "\n",
        "    def make(self) -> 'AutoregressiveDecoder':\n",
        "      return AutoregressiveDecoder(self, name=self.name)\n",
        "\n",
        "  config: Config\n",
        "\n",
        "  def setup(self) -> None:\n",
        "    self.body = self.config.body.make()\n",
        "    self.distribution = self.config.distribution.make()\n",
        "\n",
        "  def log_prob(self, data: sl.Sequence, training: bool) -> sl.Sequence:\n",
        "    \"\"\"Compute the log likelihood of the observed data.\"\"\"\n",
        "    # Shift input by one and slice one off the end.\n",
        "    # You could use a custom or learned SOS value here.\n",
        "    teacher_forcing_inputs = data.pad_time(1, 0, valid=True)[:, :-1]\n",
        "    # Compute log likelihood in parallel.\n",
        "    hidden = self.body.layer(teacher_forcing_inputs, training=training)\n",
        "    distribution = self.distribution.get_distribution(hidden, training=training)\n",
        "    return data.apply_values(lambda v: distribution.log_prob(v)).mask_invalid()\n",
        "\n",
        "  def sample(\n",
        "      self, batch_size: int, num_steps: int, training: bool, seed: jax.Array\n",
        "  ) -> sl.Sequence:\n",
        "    \"\"\"Decode step-by-step for num_steps. Uses a static unroll for clarity.\"\"\"\n",
        "    event_spec = self.distribution.event_spec\n",
        "    # The first input is all zeros to match training above.\n",
        "    x = sl.Sequence.from_values(\n",
        "        jnp.zeros((batch_size, 1) + event_spec.shape, dtype=event_spec.dtype)\n",
        "    )\n",
        "\n",
        "    # Get initial state for the step function.\n",
        "    state = self.body.get_initial_state(\n",
        "        batch_size, x.channel_spec, training=training\n",
        "    )\n",
        "\n",
        "    # Decode for a fixed number of steps.\n",
        "    xs = []\n",
        "    for _ in range(num_steps):\n",
        "      hidden, state = self.body.step(x, state, training=training)\n",
        "      distribution = self.distribution.get_distribution(\n",
        "          hidden, training=training\n",
        "      )\n",
        "      x = sl.Sequence(\n",
        "          distribution.sample(seed=seed), hidden.mask\n",
        "      ).mask_invalid()\n",
        "      xs.append(x)\n",
        "\n",
        "    # Concatenate the samples over time.\n",
        "    return sl.Sequence.concatenate_sequences(xs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1M6HFfhPFI-"
      },
      "outputs": [],
      "source": [
        "#@title Define an autoregressive categorical decoder with a transformer as the step function: {vertical-output: true}\n",
        "\n",
        "model_dimension = 1024\n",
        "num_layers = 12\n",
        "num_heads = 16\n",
        "units_per_head = 64\n",
        "ffn_dim = 4 * model_dimension\n",
        "vocab_size = 100\n",
        "dropout_rate = 0.1\n",
        "max_past_horizon = 128\n",
        "\n",
        "decoder_config = AutoregressiveDecoder.Config(\n",
        "    body=sl.Serial.Config([\n",
        "      sl.Embedding.Config(num_embeddings=vocab_size, dimension=model_dimension, name='embedding'),\n",
        "      sl.AddTimingSignal.Config(),\n",
        "      sl.Repeat.Config(\n",
        "        sl.Serial.Config([\n",
        "          # Residual self-attention module:\n",
        "          sl.Residual.Config([\n",
        "            sl.RMSNormalization.Config(name='rms_norm'),\n",
        "            sl.DotProductSelfAttention.Config(\n",
        "              units_per_head=units_per_head,\n",
        "              num_heads=num_heads,\n",
        "              max_past_horizon=max_past_horizon,\n",
        "              max_future_horizon=0,\n",
        "              use_bias=False,\n",
        "              # Use RoPE for the queries and keys.\n",
        "              query_network=sl.ApplyRotaryPositionalEncoding.Config(max_wavelength=10000),\n",
        "              key_network=sl.ApplyRotaryPositionalEncoding.Config(max_wavelength=10000),\n",
        "              attention_probabilities_dropout_rate=dropout_rate,\n",
        "              broadcast_dropout_across_queries=True,\n",
        "              name='attention'),\n",
        "            sl.DenseShaped.Config([model_dimension], use_bias=False, name='output_projection'),\n",
        "            sl.Dropout.Config(dropout_rate)\n",
        "          ], name='self_attention'),\n",
        "          # Residual feed-forward module:\n",
        "          sl.Residual.Config([\n",
        "            sl.RMSNormalization.Config(name='rms_norm'),\n",
        "            sl.Dense.Config(ffn_dim * 2, use_bias=False, name='dense1'),\n",
        "            sl.GatedUnit.Config(jax.nn.gelu, None),\n",
        "            sl.Dropout.Config(dropout_rate),\n",
        "            sl.Dense.Config(model_dimension, use_bias=False, name='dense2'),\n",
        "            sl.Dropout.Config(dropout_rate),\n",
        "          ], name='ffn'),\n",
        "        ], name='transformer_block'),\n",
        "        num_repeats=num_layers, name='transformer_blocks'),\n",
        "      sl.RMSNormalization.Config(name='output_rms_norm'),\n",
        "    ], name='transformer'),\n",
        "    distribution=Categorical.Config(num_classes=vocab_size)\n",
        ")\n",
        "\n",
        "decoder = decoder_config.make()\n",
        "\n",
        "key = jax.random.PRNGKey(1234)\n",
        "batch_size, time = 1, 512\n",
        "\n",
        "lengths = jax.random.randint(\n",
        "    key, [batch_size], minval=time // 2, maxval=time + 1\n",
        ")\n",
        "mask = np.arange(time)[jnp.newaxis, :] < lengths[:, jnp.newaxis]\n",
        "data = sl.Sequence(\n",
        "    jax.random.randint(key, [batch_size, time], minval=0, maxval=vocab_size),\n",
        "    mask\n",
        ")\n",
        "\n",
        "decoder_vars = decoder.init(key, data, training=False, method='log_prob')\n",
        "sl_utils.pprint_tree_shapes_types(decoder_vars)\n",
        "decoder = decoder.bind(decoder_vars)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pnp-U5hVNUth"
      },
      "outputs": [],
      "source": [
        "#@title Compute logprob of data.\n",
        "\n",
        "log_prob = decoder.log_prob(data, training=False)\n",
        "print(log_prob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2AL6F2lNfvc"
      },
      "outputs": [],
      "source": [
        "#@title Sample a batch.\n",
        "samples = decoder.sample(batch_size=8, num_steps=5, training=False, seed=jax.random.PRNGKey(42))\n",
        "print(samples)"
      ]
    }
  ]
}